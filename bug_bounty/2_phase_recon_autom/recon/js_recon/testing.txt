1. FINDING JS FILES------------------------------------------------------

## ‚úÖ Using Crawled URLs + `grep`

cat all_urls.txt | grep -Eo 'https?://[^ ]+\.js([?#][^ ]*)?' | sort -u | anew crawled_jsfiles.txt


## ‚úÖ Using Katana

katana -list live_subdomains.txt -jc -d 5 -o katana_all.txt
 grep -Eo 'https?://[^ ]+\.js([?#][^ ]*)?' katana_all.txt| sort -u > katana_jsfiles.txt



## ‚úÖ Using `subjs`

cat live_subdomains.txt | subjs >>subjs_jsfiles.txt
cat allurls.txt | subjs | sort -u >> subjs_jsfiles.txt


##COMBINING ALL FILES:
cat crawled_jsfiles.txt katana_jsfiles.txt subjs_jsfiles.txt | sort -u >>alljs.txt

##FILTERING:
httpx -mc 200 -silent -o livejs.txt < alljs.txt



------------------------------------------------------------------------------



2. DOWNLOADING JS FILES

cat livejs.txt | xargs -I {} wget --content-disposition -q -P js_downloads {}


------------------------------------------------------------------------------

# üïµÔ∏è‚Äç‚ôÇÔ∏è MANUAL REVIEW & STATIC ANALYSIS

## üìö Tools:

---

Using linkfinder:

mkdir linkfinder_results

while read domain; do   echo "[+] Scanning $domain";   python3 /home/maddy/techiee/bug_bounty/2_phase_recon_autom/recon/js_recon/LinkFinder/linkfinder.py -i "$domain" -d -o cli | tee "linkfinder_results/$(echo $domain | sed 's|https\?://||;s|/|_|g')_results.txt"; done < oi 

while read domain; do   echo "[+] Scanning $domain";   output_file="linkfinder_results/$(echo $domain | sed 's|https\?://||;s|/|_|g').html";   python3 /home/maddy/techiee/bug_bounty/2_phase_recon_autom/recon/js_recon/LinkFinder/linkfinder.py -i "$domain" -d -o "$output_file"; done < domains.txt

python3 /home/maddy/techiee/bug_bounty/2_phase_recon_autom/recon/js_recon/LinkFinder/linkfinder.py -i '/home/maddy/sam/js_downloads/*' -o cli | tee linkfinder_results/linkfinder_cli_results_jscontents
python3 /home/maddy/techiee/bug_bounty/2_phase_recon_autom/recon/js_recon/LinkFinder/linkfinder.py -i '/home/maddy/sam/js_downloads/*' -o linkfinder_results/linkfinder_html_results_jscontents


Look for:

    Endpoints (/api/user/update, /admin/config)
    API Keys, secrets, tokens
    JWT endpoints, S3 buckets

    ‚úÖ Secret Trick: Run regex searches on downloaded JS files to find auth headers, tokens, and debug endpoints.


## 1Ô∏è‚É£ Token/Key Extraction (Manual grep)


cat js_downloads/* | grep -Eo "/api/[a-zA-Z0-9_/-]+" | sort -u >>api_endpoints
```
long alphanumeric dtrings:
cat js_downloads/* | grep -EHo '([A-Za-z0-9_]{15,})' | tee strings.txt

basic auth tokens:
cat js_downloads/* | grep -Ei 'Basic[\s\-_A-Za-z0-9]*[:=][\s\-_A-Za-z0-9]{10,}' | tee auth_tokens.txt

sens keyword:
grep -Poir --exclude='*.min.js' --binary-files=without-match   -e '.{0,15}(api[_-]?key|secret|token|authorization|bearer|client[_-]?id|client[_-]?secret|jwt|admin|pass(word)?|cred(entials)?).{0,15}'   js_downloads/ | sed -E 's/(api[_-]?key|secret|token|authorization|bearer|client[_-]?id|client[_-]?secret|jwt|admin|pass(word)?|cred(entials)?)/\x1b[31m\1\x1b[0m/Ig' > sens_keys_short.txt




## 3Ô∏è‚É£ `SecretFinder`


mkdir secretfinder_results

python3 /home/maddy/techiee/bug_bounty/2_phase_recon_autom/recon/js_recon/SecretFinder/SecretFinder.py -i 'js_downloads/*' -o cli | tee secretfinder_results/results.txt



# Crawl and analyze all JS on domain
python3 SecretFinder.py -i https://empireflippers.com/ -e -o output

python3 /home/maddy/techiee/bug_bounty/2_phase_recon_autom/recon/js_recon/SecretFinder/SecretFinder.py -i https://empireflippers.com/ -e -o output_html_automated

`python3 /home/maddy/techiee/bug_bounty/2_phase_recon_autom/recon/js_recon/SecretFinder/SecretFinder.py -i https://empireflippers.com/ -e -o cli | tee output.txt_automated

## 4Ô∏è‚É£ `mantra`

mkdir /mantra
cat livejs.txt | mantra | tee mantra/mantra_results.txt
```

## 5Ô∏è‚É£ `lazyegg`

```bash
python lazyegg.py http://target.com || output
 cat livejs.txt | xargs -I{} bash -c 'echo -e "\ntarget : {}\n" && python3 /home/maddy/techiee/bug_bounty/2_phase_recon_autom/recon/js_recon/lazyegg/lazyegg.py "{}" --js_urls --domains --ips --leaked_creds'


## 6Ô∏è‚É£ `nuclei` JS Exposure Detection

mkdir nuclei-res/
nuclei -l js.txt -t ~/nuclei-templates/exposures/ -o  nuclei-res/js_exposures_results.txt
nuclei -l js.txt -o  nuclei-res/js_outputs

# Custom templates
cat samsung.txt | nuclei -t prsnl/credentials-disclosure-all.yaml -c 30
```

## 7Ô∏è‚É£ S3 Bucket Takeover

```bash
# Find S3 bucket URLs
cat vul3.txt | xargs -I% curl -sk "%" | grep -Eo '([a-z0-9\.-]+)\.s3.*\.amazonaws\.com' >> s3_bucket.txt

# Extract bucket names
cat s3_bucket.txt | sed 's/.*s3.*\.amazonaws\.com\///' | sort -u > bucket_name.txt

# Test write/delete with AWS CLI
cat bucket_name.txt | xargs -I% sh -c 'aws s3 cp test.txt s3://% 2>&1 | grep "upload" && echo "[+] Writable: %"'
cat bucket_name.txt | xargs -I% sh -c 'aws s3 rm s3://%/test.txt 2>&1 | grep "delete" && echo "[+] Deletable: %"'
```

## 8Ô∏è‚É£ JSFScan 

```bash
bash JSFScan.sh -l domains.txt -all -r -o results
```



---

# üíª Burp for Deep Analysis

* Use JSFinder + JSLuice++ extensions.
* Analyze request/response structure.
* Discover endpoints, tokens, and cookie manipulation.
## ‚úÖ Using Burp Suite

* Use HTTP history and sitemap to filter JS.
* Use **JSFinder** & **jsluice++** Burp extensions.


* Use **[de4js](https://lelinhtinh.github.io/de4js/)** to beautify/obfuscate JS.
* Ask ChatGPT for interpreting suspicious code blocks or endpoints.

